import torch
from torch import nn
from d2l import torch as d2l
from torch.utils.tensorboard import SummaryWriter
import os
from datetime import datetime

# å…³é—­TensorFlowè­¦å‘Šä¿¡æ¯
import warnings
warnings.filterwarnings('ignore')
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

net = nn.Sequential(
    nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(), # padding=2è¡¨ç¤ºåœ¨æ¯ä¸€è¾¹å¡«å……2è¡Œæˆ–2åˆ—
    nn.AvgPool2d(kernel_size=2, stride=2), # æ± åŒ–å±‚ï¼Œkernel_size=2è¡¨ç¤ºæ± åŒ–çª—å£ä¸º2x2ï¼Œstride=2è¡¨ç¤ºæ­¥å¹…ä¸º2
    nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(), # è¿™é‡Œæ²¡æœ‰å¡«å……ï¼Œæ‰€ä»¥è¾“å‡ºçš„é«˜å’Œå®½ä¼šå‡å°
    nn.AvgPool2d(kernel_size=2, stride=2), # æ± åŒ–å±‚ï¼Œkernel_size=2è¡¨ç¤ºæ± åŒ–çª—å£ä¸º2x2ï¼Œstride=2è¡¨ç¤ºæ­¥å¹…ä¸º2
    nn.Flatten(), # å±•å¹³å¤šç»´çš„è¾“å…¥æ•°æ®ä¸ºäºŒç»´
    nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(), # å°†16ä¸ª5x5ç‰¹å¾å›¾å±•å¹³ä¸º400ç»´å‘é‡ï¼Œæ˜ å°„åˆ°120ä¸ªéšè—å•å…ƒ
    nn.Linear(120, 84), nn.Sigmoid(), # 120æŒ‡çš„æ˜¯å‰ä¸€å±‚çš„è¾“å‡ºï¼Œæ˜ å°„åˆ°84ä¸ªéšè—å•å…ƒ
    nn.Linear(84, 10))
# nn.Dense() # å…¨è¿æ¥å±‚ï¼Œç­‰ä»·äºnn.Linear()
# nn.Dropout() # Dropoutå±‚ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
# nn.ReLU() # ReLUæ¿€æ´»å‡½æ•°ï¼ŒLeNet-5åŸç‰ˆä½¿ç”¨sigmoidï¼Œä½†æ˜¯AlexNetç­‰åç»­ç½‘ç»œå‘ç°ReLUæ›´å¥½
# Conv2d å·ç§¯å±‚ -> Sigmoid æ¿€æ´»å‡½æ•° -> AvgPool2d æ± åŒ–å±‚ -> Conv2d å·ç§¯å±‚ -> Sigmoid æ¿€æ´»å‡½æ•° 
# -> AvgPool2d æ± åŒ–å±‚ -> Flatten å±•å¹³ -> Linear å…¨è¿æ¥å±‚ -> Sigmoid æ¿€æ´»å‡½æ•° -> Linear å…¨è¿æ¥å±‚ 
# -> Sigmoid æ¿€æ´»å‡½æ•° -> Linear å…¨è¿æ¥å±‚
# æ€»å…±10å±‚ï¼š 2ä¸ªå·ç§¯å±‚ï¼Œ2ä¸ªæ± åŒ–å±‚ï¼Œ1ä¸ªå±•å¹³å±‚ï¼Œ3ä¸ªå…¨è¿æ¥å±‚ï¼Œ3ä¸ªæ¿€æ´»å‡½æ•°å±‚
# è¿™æ˜¯LeNet-5ç½‘ç»œç»“æ„

X = torch.rand(size=(1, 1, 28, 28), dtype=torch.float32)

batch_size = 256
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)

# è¯„ä¼°æ¨¡å‹åœ¨GPUä¸Šçš„å‡†ç¡®ç‡
def evaluate_accuracy_gpu(net, data_iter, device=None): #@save
    """ä½¿ç”¨GPUè®¡ç®—æ¨¡å‹åœ¨æ•°æ®é›†ä¸Šçš„ç²¾åº¦"""
    if isinstance(net, nn.Module):
        net.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        if not device:
            device = next(iter(net.parameters())).device
    # æ­£ç¡®é¢„æµ‹çš„æ•°é‡ï¼Œæ€»é¢„æµ‹çš„æ•°é‡
    metric = d2l.Accumulator(2)
    with torch.no_grad():
        for X, y in data_iter:
            if isinstance(X, list):
                # BERTå¾®è°ƒæ‰€éœ€çš„
                X = [x.to(device) for x in X]
            else:
                X = X.to(device)
            y = y.to(device)
            metric.add(d2l.accuracy(net(X), y), y.numel())
    return metric[0] / metric[1]

# è®­ç»ƒæ¨¡å‹
#@save
def train_ch6(net, train_iter, test_iter, num_epochs, lr, device):
    """ç”¨GPUè®­ç»ƒæ¨¡å‹"""
    def init_weights(m): # åˆå§‹åŒ–æ¨¡å‹å‚æ•°
        if type(m) == nn.Linear or type(m) == nn.Conv2d: # å¦‚æœæ˜¯çº¿æ€§å±‚æˆ–å·ç§¯å±‚
            nn.init.xavier_uniform_(m.weight) # Xavierå‡åŒ€åˆ†å¸ƒåˆå§‹åŒ–ï¼Œé€‚åˆäºSigmoidæ¿€æ´»å‡½æ•°
            # ä¸ç”¨æ­£æ€åˆ†å¸ƒåˆå§‹åŒ–ï¼Œå› ä¸ºæ­£æ€åˆ†å¸ƒåˆå§‹åŒ–ä¼šä½¿å¾—æƒé‡è¿‡å¤§æˆ–è¿‡å°ï¼Œå¯¼è‡´æ¢¯åº¦æ¶ˆå¤±æˆ–çˆ†ç‚¸
    net.apply(init_weights) # åˆå§‹åŒ–æ¨¡å‹å‚æ•°
    print('training on', device)
    net.to(device) # å°†æ¨¡å‹å‚æ•°å¤åˆ¶åˆ°deviceä¸Šï¼Œdeviceå¯ä»¥æ˜¯'cpu'æˆ–'cuda'
    
    # è®¾ç½®TensorBoard
    log_dir = f"runs/LeNet_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    writer = SummaryWriter(log_dir)
    print(f'TensorBoard logs saving to: {log_dir}')
    print('Run: tensorboard --logdir=runs')
    
    # optimizer = torch.optim.SGD(net.parameters(), lr=lr) # éšæœºæ¢¯åº¦ä¸‹é™ä¼˜åŒ–å™¨
    optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=1e-4) # Adamä¼˜åŒ–å™¨ + æƒé‡è¡°å‡
    loss = nn.CrossEntropyLoss() # äº¤å‰ç†µ
    timer, num_batches = d2l.Timer(), len(train_iter) # è®¡æ—¶å™¨ï¼Œè®­ç»ƒæ‰¹æ¬¡æ•°
    
    # è®°å½•æ¨¡å‹ç»“æ„åˆ°TensorBoard
    dummy_input = torch.randn(1, 1, 28, 28).to(device)
    writer.add_graph(net, dummy_input)
    # è®­ç»ƒå‘¨æœŸ
    for epoch in range(num_epochs):
        # è®­ç»ƒæŸå¤±ä¹‹å’Œï¼Œè®­ç»ƒå‡†ç¡®ç‡ä¹‹å’Œï¼Œæ ·æœ¬æ•°
        metric = d2l.Accumulator(3) # è®­ç»ƒæŸå¤±ä¹‹å’Œï¼Œè®­ç»ƒå‡†ç¡®ç‡ä¹‹å’Œï¼Œæ ·æœ¬æ•°
         # è®­ç»ƒæ¨¡å¼
        net.train()
        for i, (X, y) in enumerate(train_iter): # éå†è®­ç»ƒæ•°æ®é›†
            timer.start()
            optimizer.zero_grad() # æ¢¯åº¦æ¸…é›¶
            X, y = X.to(device), y.to(device) # å°†æ•°æ®å¤åˆ¶åˆ°deviceä¸Š
            y_hat = net(X) # å‰å‘è®¡ç®—
            l = loss(y_hat, y) # è®¡ç®—æŸå¤±
            l.backward() # åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦
            optimizer.step() # æ›´æ–°å‚æ•°
            with torch.no_grad():
                metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0]) # ç´¯åŠ æŸå¤±ã€å‡†ç¡®ç‡ã€æ ·æœ¬æ•°
            timer.stop() 
            train_l = metric[0] / metric[2] # å¹³å‡æŸå¤±
            train_acc = metric[1] / metric[2] # å¹³å‡å‡†ç¡®ç‡
            
            # è®°å½•è®­ç»ƒè¿‡ç¨‹åˆ°TensorBoardï¼ˆæ¯100ä¸ªbatchè®°å½•ä¸€æ¬¡ï¼‰
            global_step = epoch * num_batches + i
            if (i + 1) % 100 == 0 or i == num_batches - 1:
                writer.add_scalar('Loss/Train', train_l, global_step)
                writer.add_scalar('Accuracy/Train', train_acc, global_step)
                
        # æ¯ä¸ªepochç»“æŸåè®°å½•æµ‹è¯•å‡†ç¡®ç‡
        test_acc = evaluate_accuracy_gpu(net, test_iter)
        writer.add_scalar('Accuracy/Test', test_acc, epoch)
        
        # è®°å½•å­¦ä¹ ç‡
        writer.add_scalar('Learning_Rate', optimizer.param_groups[0]['lr'], epoch)
        
        # è®°å½•æƒé‡å’Œæ¢¯åº¦çš„ç›´æ–¹å›¾ï¼ˆæ¯5ä¸ªepochè®°å½•ä¸€æ¬¡ï¼‰
        if epoch % 5 == 0:
            for name, param in net.named_parameters():
                writer.add_histogram(f'Weights/{name}', param, epoch)
                if param.grad is not None:
                    writer.add_histogram(f'Gradients/{name}', param.grad, epoch)
        
        print(f'epoch {epoch + 1}, loss {train_l:.3f}, train acc {train_acc:.3f}, test acc {test_acc:.3f}')
    
    # å…³é—­TensorBoard writer
    writer.close()
    
    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '
          f'test acc {test_acc:.3f}')
    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '
          f'on {str(device)}')
    print(f'TensorBoard logs saved to: {log_dir}')
    print('To view results, run: tensorboard --logdir=runs')
    
lr, num_epochs = 0.001, 10  # å­¦ä¹ ç‡ï¼šAdamé€šå¸¸ç”¨0.001
# TensorBoard ä½¿ç”¨è¯´æ˜
"""
ğŸ¯ TensorBoard å¯è§†åŒ–åŠŸèƒ½ï¼š

1. ğŸ“Š è®­ç»ƒæŸå¤±å’Œå‡†ç¡®ç‡æ›²çº¿
2. ğŸ§  æ¨¡å‹ç»“æ„å›¾
3. ğŸ“ˆ æƒé‡å’Œæ¢¯åº¦åˆ†å¸ƒç›´æ–¹å›¾
4. âš¡ å­¦ä¹ ç‡å˜åŒ–
5. ğŸ¨ å›¾åƒæ ·æœ¬ï¼ˆå¯é€‰ï¼‰

ğŸš€ ä½¿ç”¨æ­¥éª¤ï¼š
1. è¿è¡Œè®­ç»ƒè„šæœ¬
2. æ‰“å¼€ç»ˆç«¯ï¼Œè¿è¡Œ: tensorboard --logdir=runs
3. åœ¨æµè§ˆå™¨æ‰“å¼€: http://localhost:6006
4. æŸ¥çœ‹å„ç§å¯è§†åŒ–å›¾è¡¨

ğŸ“ æ—¥å¿—æ–‡ä»¶ä¿å­˜åœ¨: runs/LeNet_YYYYMMDD_HHMMSS/
"""

def log_sample_images(writer, data_iter, device, epoch=0):
    """è®°å½•æ ·æœ¬å›¾åƒåˆ°TensorBoard"""
    # è·å–ä¸€æ‰¹æ ·æœ¬
    images, labels = next(iter(data_iter))
    images = images[:8].to(device)  # åªå–å‰8ä¸ªæ ·æœ¬
    labels = labels[:8].to(device)
    
    # è®°å½•åŸå§‹å›¾åƒ
    writer.add_images('Sample_Images/Original', images, epoch)
    
    # è®°å½•é¢„æµ‹ç»“æœ
    net.eval()
    with torch.no_grad():
        predictions = net(images)
        predicted_labels = predictions.argmax(dim=1)
    
    # åˆ›å»ºæ ‡é¢˜ï¼ˆçœŸå®æ ‡ç­¾ vs é¢„æµ‹æ ‡ç­¾ï¼‰
    class_names = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat',
                   'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']
    
    for i in range(len(images)):
        true_label = class_names[labels[i]]
        pred_label = class_names[predicted_labels[i]]
        writer.add_text(f'Predictions/Sample_{i}', 
                       f'True: {true_label}, Pred: {pred_label}', epoch)

# ä¸»è®­ç»ƒæ‰§è¡Œ
if __name__ == '__main__':
    print("ğŸš€ å¼€å§‹è®­ç»ƒLeNet-5æ¨¡å‹...")
    print("ğŸ“Š ä½¿ç”¨TensorBoardè¿›è¡Œå¯è§†åŒ–ç›‘æ§")
    print("-" * 50)
    
    # æ£€æŸ¥è®¾å¤‡
    device = d2l.try_gpu()
    print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # å¼€å§‹è®­ç»ƒ
    train_ch6(net, train_iter, test_iter, num_epochs, lr, device)
    
    print("\n" + "="*50)
    print("ğŸ‰ è®­ç»ƒå®Œæˆï¼")
    print("ğŸ“Š æŸ¥çœ‹TensorBoard:")
    print("   1. æ‰“å¼€ç»ˆç«¯")
    print("   2. è¿è¡Œ: tensorboard --logdir=runs")
    print("   3. æ‰“å¼€æµè§ˆå™¨: http://localhost:6006")
    print("="*50)