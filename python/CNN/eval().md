简单来说，`net.eval()` 是将你的神经网络切换到 **“评估模式”** 或 **“推理模式”**。

我们可以用一个生动的比喻来理解：

*   `net.train()`: **学习/训练模式**。这就像学生在上课和做练习题。他会积极学习新知识，甚至会用一些特殊的学习技巧（比如故意忘记一些东西来强迫自己记忆，即 Dropout）。
*   `net.eval()`: **考试模式**。这就像学生在参加正式考试。他必须拿出全部所学，全力以赴，不能再使用任何“学习技巧”，并且每次做同一道题都必须得到同样稳定的答案。

---

### `net.eval()` 到底做了什么？

当你调用 `net.eval()` 时，它并不会停止梯度计算或改变模型的权重。它主要会影响网络中**特定层**的行为，让它们在训练和评估时表现不同。最重要的两个层是：

#### 1. Dropout 层

*   **在训练模式 (`net.train()`) 下**：Dropout 层会按照设定的概率 `p` **随机地“关闭”** 一些神经元。这是一种正则化技术，用于防止模型过拟合，强迫网络学习到更鲁棒的特征。
*   **在评估模式 (`net.eval()`) 下**：Dropout 层**会被完全禁用**。在预测时，我们希望使用整个网络的全部能力，而不是随机关闭一部分。所以 `net.eval()` 会确保所有神经元都处于激活状态，让网络做出最稳定、最准确的预测。

#### 2. Batch Normalization (BN) 层

这是 `net.eval()` **最重要**的影响所在。

*   **在训练模式 (`net.train()`) 下**：BN 层会计算**当前批次（mini-batch）数据**的均值和方差，并用它们来归一化数据。同时，它还会维护一个全局的“运行均值”和“运行方差”，这个全局值是根据训练过程中所有批次的统计数据动态更新的。
*   **在评估模式 (`net.eval()`) 下**：BN 层会**停止使用当前批次的统计数据**。为什么？因为在评估时，你可能只输入一张图片，或者一个很小的批次，这个小批次的均值和方差可能非常不稳定，会严重影响最终结果。因此，`net.eval()` 会让 BN 层**固定下来，转而使用在整个训练集上学习到的、更稳定、更具代表性的全局“运行均值”和“运行方差”**。

---

### 和 `torch.no_grad()` 的关系

初学者经常将 `net.eval()` 和 `torch.no_grad()` 混淆。它们是两个**不同但通常一起使用**的东西。

*   `net.eval()`: **改变网络层的行为**（如 Dropout 和 BN）。它不影响梯度计算。
*   `torch.no_grad()`: 这是一个**上下文管理器**，它告诉 PyTorch 在其作用域内**不要计算梯度**。

**为什么它们通常一起使用？**
在评估模型时，我们只关心前向传播的预测结果，不需要计算梯度来进行反向传播和权重更新。关闭梯度计算可以：
1.  **大大减少内存消耗**，因为不需要存储中间变量用于求导。
2.  **显著加快计算速度**。

### 正确的使用方法

**黄金法则:**

1.  在开始**训练**你的模型之前，调用 `net.train()`。
2.  在开始**评估**（验证或测试）你的模型之前，调用 `net.eval()`，并把评估代码放在 `with torch.no_grad():` 代码块中。

**示例代码:**

```python
# 训练循环
net.train() # 切换到训练模式
for data, target in train_loader:
    optimizer.zero_grad()
    output = net(data)
    loss = criterion(output, target)
    loss.backward()
    optimizer.step()

# 验证/测试循环
net.eval() # 切换到评估模式
correct = 0
total = 0
with torch.no_grad(): # 在这个代码块中，不计算梯度
    for data, target in test_loader:
        output = net(data)
        _, predicted = torch.max(output.data, 1)
        total += target.size(0)
        correct += (predicted == target).sum().item()

print(f'Accuracy: {100 * correct / total}%')
```

### 总结

| | `net.train()` (训练模式) | `net.eval()` (评估模式) |
| :--- | :--- | :--- |
| **Dropout** | **激活** (随机失活神经元) | **关闭** (所有神经元都工作) |
| **Batch Norm**| 使用**当前批次**的均值/方差 | 使用**全局运行**的均值/方差 |
| **梯度** | (默认计算梯度) | (本身不影响，但通常与 `torch.no_grad()` 配合使用) |
| **目的** | 学习模型参数 | 评估模型性能，进行预测 |